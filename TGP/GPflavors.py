#-----------------------------------------------------------------------------------#
# This file contains the implementations of the different population dynamics       #
# (or GP flavors) a GP can perform, such as, Steady State, Cellular (Toroidal-grid) #
# and even a modified Hill Climbing.                                                #
#
# All methodos receive as input: (1) the current Popultation, (2) the training set, #
# both samples and labels (considering supervised learning), (3) parameters that    #
# specify things suchas size of the offspring pool, selection mechanisms, list of   #
# genetic operations to be used along their probability and arity, and (4) if the   #
# procedure will perform incremental (on-line) learning, in which case it must re-  #
# evaluate the current population (not only the new one) against the current mini-  #
# batch (because it has changed since the previous generation).                     #
#
# The output all these mechanisms return is a new, already evaluated, population, ie#
# the next gen. They also return a phenotypic measure of diversity (measured from   #
# couting all different fitness values found in the population divided by the pop   #
# size) as well as the fitness value of the best individual and its performance in  #
# in a testing set (if provided).                                                   #
#
# It is important to stress that these mechanisms are implemented to perform a      #
# single evolutionary cycle, that is, the management of number generations or epochs#
# (i.e., cycles) are left to a higher level method, which is supossed to call these #
# functions as much as needed.                                                      #
#
# This file is part of TurboGP, a Python library for Genetic Programming (Koza,1992)#
# by Rodriguez-Coayahuitl, Morales-Reyes, HJ Escalante. 2020.                       #
# Instituto Nacional de Astrofisica, Optica y Electronica (INAOE). Puebla, Mexico   #
# Development funded by CONACyT grant No. 436184, CONCyTEP grant 2019-52D, and INAOE#
# Distributed under GNU General Public License                                      #
#-----------------------------------------------------------------------------------#

from functools import partial
from multiprocessing import Pool
from GPIndividuals import *
from GPOperators import *
from LowLevel import *
from Mezzanine import *
from HighLevel import *

from Utils import *
from GPUtils import *

import numpy as np
import random

def evaluate_fitness_in_parallel(individual, batch, labels):
    '''This is a wrapper function useful to parallelize individual evaluation through the
    use of multiprocessing Pool function. Doesn t do anything other really than that.
    Requires as input an individual to be evaluated and the batch which is going to be
    evaluated against (and its corresponding labels).
    Returns as output the fitness value. It is important to remark that this fitness value
    needs to be captured by the invoking function, because when individuals evaluation gets
    parallelized they cannot save their own fitness value when fitness() evaluating member
    method is called, and the invoking function needs to assign them manually.'''

    fitness_value = individual.fitness(batch, labels)

    return fitness_value



def Steady_State(Population, batch, labels, test_batch, test_labels, l_rate, oper, oper_prob, oper_arity, minimization, sel_mechanism, online, pro=None):
    '''This is the Steady State flavour of a GP evolutionary cycle. It receives as input a
    population (must be already evaluated), a training set (batch and labels), the size of
    the parents/offspring pool (l_rate), a list indicating the genetic operations to be used
    (oper), a vector of probabilities for each operation (oper_prob), the arity of each
    operation (oper_arity), if it is a minimzation problem (or not, i.e. a maximization one),
    the desired selection mechanism to use, and if the learning is on-line (incremental /
    mini-batch based).

    This version of Steady State besides returning the new population, it also returns the
    diversity measure based on phenotypic differences (i.e. how many different fitnessess
    values are found in the new population), and the best fitness value for the training
    set.

    test_batch and test_labels are optional; if provided then the function evaluates the
    best performing individual of the generation against them, to provide a testing fitness
    score as well. '''



    np.random.seed()
    random.seed()

    pop_size = len(Population)

    # Determine how many individuals will be generated by each operation
    no_oper = [int((pop_size * l_rate * probability)/offspring_generated) for (probability,offspring_generated) in zip(oper_prob,oper_arity)]

    # Build pool of parents
    parents_pool = sel_mechanism(population=Population, proportion=l_rate, minimization=minimization)

    # Create a pool for the offspring
    Offspring = []

    # Apply operations
    for (gpoperation, arity, no) in zip(oper, oper_arity, no_oper):
        for _ in range(no):
            # Pick parents
            parents = [random.choice(parents_pool) for _ in range(arity)]
            # Cross/Mutate them
            offsprings = gpoperation(*parents)

            if type(offsprings) is tuple:
                Offspring.extend(offsprings)
            else:
                Offspring.append(offsprings)


    # Now we have to evaluate both, the offspring and the original pop (if online==True; otherwise just the offspring)
    if online == True:
        for individual in Population:
            individual.fitness(batch, labels)
    for individual in Offspring:
        individual.fitness(batch, labels)

    # Create container for new pop
    New_Pop = []

    # Use elite selection mechanism to build new pop. This is a deterministic selection mechanim, though
    # it might as well be replaced with a stochastic evolutionary selection method.
    # Here we use a 50/50 scheme.

    selected_original = elite_selection(population=Population, amount=(pop_size // 2), minimization=minimization)
    selected_offspring = elite_selection(population=Offspring, amount=(pop_size // 2), minimization=minimization)

    #selected_original = elite_selection(population=Population, amount=(pop_size - 1), minimization=minimization)
    #selected_offspring = elite_selection(population=Offspring, amount=(1), minimization=minimization)

    New_Pop.extend(selected_original)
    New_Pop.extend(selected_offspring)

    # Enumerate all fitnesses:
    L = []
    for individual in New_Pop:
        L.append(individual.fitness_value)
    # Count how many fitnesses are actually different
    no_different = len(set(L))
    # Diversity as a proportion of different fitnesses over population size
    diversity = no_different / len(New_Pop)

    if minimization:
        best_fit = min(L)
    else:
        best_fit = max(L)


    if test_batch is not None:
        # Pick top performer
        top_individual = elite_selection(population=Population, amount=1, minimization=minimization)[0]
        # Test it against test set
        test_fit = top_individual.fitness(test_batch, test_labels)
        # Restore top individual fitness according to current generation training batch:
        top_individual.fitness(batch, labels)
    else:
        test_fit = None


    return New_Pop, diversity, best_fit, test_fit


def Steady_StateMP(Population, batch, labels, test_batch, test_labels, l_rate, oper, oper_prob, oper_arity, minimization, sel_mechanism, online, pro):
    '''Same as Steady_State, but with an additional parameter: "pro" (int) that specifies how many cores will be used
    to evaluate population and offspring pools. This is individual-level parallelization, that means that individuals
    fitness evaluation will be split across all cores allocated. Make sure not to use a parallel sample evaluation-
    enabled type of individual (i.e. one that parallelize sample evaluations) nor the automatic parellization of Open
    BLAS/MKLBlas is enabled (they are, by default, on modern Python distributions) or you could not get any performance
    gain due to parallelization ocurring at different levels and blocking CPUs instructions paths.'''

    np.random.seed()
    random.seed()

    pop_size = len(Population)

    # Determine how many individuals will be generated by each operation
    no_oper = [int((pop_size * l_rate * probability)/offspring_generated) for (probability,offspring_generated) in zip(oper_prob,oper_arity)]

    # Build pool of parents
    parents_pool = sel_mechanism(population=Population, proportion=l_rate, minimization=minimization)

    # Create a pool for the offspring
    Offspring = []

    # Apply operations
    for (gpoperation, arity, no) in zip(oper, oper_arity, no_oper):
        for _ in range(no):
            # Pick parents
            parents = [random.choice(parents_pool) for _ in range(arity)]
            # Cross/Mutate them
            offsprings = gpoperation(*parents)

            if type(offsprings) is tuple:
                Offspring.extend(offsprings)
            else:
                Offspring.append(offsprings)

    #-------------------------------------------------------------------------------------------
    #------------------- Parallel Multiprocessor Individuals Evaluation-------------------------
    #-------------------------------------------------------------------------------------------

    with Pool(pro) as p:

        func = partial(evaluate_fitness_in_parallel,
                       batch = batch,
                       labels = labels)

        if online == True:
            Population_fitnesses = p.map(func, Population)
        Offspring_fitnesses = p.map(func, Offspring)

    # Assign fitness values manually
    if online == True:
        for i in range(len(Population)):
            Population[i].fitness_value = Population_fitnesses[i]
    for i in range(len(Offspring)):
        Offspring[i].fitness_value = Offspring_fitnesses[i]

    #--------------------------------------------------------------------------------------------
    #--------------------------------------------------------------------------------------------

    # Create container for new pop
    New_Pop = []

    # Use elite selection mechanim to build new pop. This is an impartial selection mechanims, though
    # it might as well be replaced with a conventional stochastic evolutionary selection mechanism.
    # We are gonna use a 50/50 scheme, though this should adapted into a parameter in future releases

    selected_original = elite_selection(population=Population, amount=(pop_size // 2), minimization=minimization)
    selected_offspring = elite_selection(population=Offspring, amount=(pop_size // 2), minimization=minimization)

    New_Pop.extend(selected_original)
    New_Pop.extend(selected_offspring)

    # Enumerate all fitnesses:
    L = []
    for individual in New_Pop:
        L.append(individual.fitness_value)
    # Count how many fitnesses are actually different
    no_different = len(set(L))
    # Diversity as a proportion of different fitnesses over population size
    diversity = no_different / len(New_Pop)

    if minimization:
        best_fit = min(L)
    else:
        best_fit = max(L)


    if test_batch is not None:
        # Pick top performer
        top_individual = elite_selection(population=Population, amount=1, minimization=minimization)[0]
        # Test it against test set
        test_fit = top_individual.fitness(test_batch, test_labels)
        # Restore top individual fitness according to current generation training batch:
        top_individual.fitness(batch, labels)
    else:
        test_fit = None

    # Return best individual (for usage purposes)
    #result = elite_selection(population=New_Pop, amount=1, minimization=minimization)

    return New_Pop, diversity, best_fit, test_fit


def Cellular(Population, batch, labels, test_batch, test_labels, l_rate, oper, oper_prob, oper_arity, minimization, sel_mechanism, online, pro=None, neighborhood='von Neumann', beta=-1, r_policy='1to1SteadyState'):
    '''This is a spatially distributed population, a cellular arragement, in grid-toroidal form. In this model
    individuals reside in individual cells, and can only mate with their neighbors. This model can work either as as
    steady state or generational replacement dynamic (r_policy). In 1to11to1SteadyState (default) a single offspring
    is generated by randomly picking some of the best possible parents within the cell neighborhood; this new individual
    competes against the residing individual, if fitness is better, then it replaces the original one, otherwise the
    residing individual remains. In generational replacement the offspring always replaces the original individual. If
    neither 1to1SteadyState nor generational replacement are used, then a special mode that allows migration of original
    individuals from neighboring cells to the cell being evaluated is used; it is unadvised to use such method, since
    diversity might deplete too quickly.

    Neighborhood can be in the shape of either von_newman (default) or Moore.

    Notice how, unlike in standard steady state, only one offspring is generated in each cell being processed; this
    means that even if crossover is used to generate offspring, only one of the offspring generated will be randomly
    picked to compete against the individual within the cell, while the other offspring will be discarded without
    evaluation. This has to be done this way, because otherwise the number of evaluations would become larger than the
    actual size of the population. In this regard, it should be noted that this particular population model can be
    found in the literature described in many different forms (e.g. evaluating both offspring generated by a crossover
    operation); in TurboGP we implemented it in this way, but its behavior may be easily modified by toying around with
    the code below.

    Beta parameter can also be sent to this method from outside, ie. from the calling function that iterates over this
    method, in order to perform 'centric selection' (based on the work of Simoncini et al. (2009).'''

    np.random.seed()
    random.seed()

    # Process every cell

    Offspring_grid = []
    r = len(Population)

    for row in range(len(Population)):

        New_Row = []
        c = len(Population[row])

        for i in range(len(Population[row])):

            # create neighborhood
            neigh = []

            if np.random.uniform() <= beta:

                neigh.append(Population[row][i])
                operation = np.random.choice(a=list(range(len(oper))), p=oper_prob)
                gpoperation = oper[operation]
                arity = oper_arity[operation]
                parents_minipool = elite_selection(population=neigh, amount=1, minimization=minimization)

            else:

                #neigh.append(Population[row-1][i-1])
                neigh.append(Population[row-1][i])
                #neigh.append(Population[row-1][(i+1)%c])

                neigh.append(Population[row][i-1])
                neigh.append(Population[row][i])
                neigh.append(Population[row][(i+1)%c])

                #neigh.append(Population[(row+1)%r][i-1])
                neigh.append(Population[(row+1)%r][i])
                #neigh.append(Population[(row+1)%r][(i+1)%c])

                if neighborhood == 'Moore':

                    neigh.append(Population[row-1][i-1])
                    neigh.append(Population[row-1][(i+1)%c])

                    neigh.append(Population[(row+1)%r][i-1])
                    neigh.append(Population[(row+1)%r][(i+1)%c])

                operation = np.random.choice(a=list(range(len(oper))), p=oper_prob)
                gpoperation = oper[operation]
                arity = oper_arity[operation]
                parents_minipool = sel_mechanism(population=neigh, proportion=l_rate, minimization=minimization)


            # Create and evaluate offspring
            #Offspring = []

            # Pick parents
            parents = [random.choice(parents_minipool) for _ in range(arity)]
            # Cross/Mutate them
            offsprings = gpoperation(*parents)

            if type(offsprings) is tuple:
                # there can be only one
                Offspring = np.random.choice(offsprings)
            else:
                Offspring = offsprings

            # Append Offspring
            New_Row.append(Offspring)

        # Append row
        Offspring_grid.append(New_Row)


    # evaluate original grid
    if online == True:
        for a in range(len(Population)):
            for b in range(len(Population[a])):
                Population[a][b].fitness(batch, labels)
    # Evaluate Offspring
    for a in range(len(Offspring_grid)):
        for b in range(len(Offspring_grid[a])):
            Offspring_grid[a][b].fitness(batch, labels)




    # Build next pop

    L = []
    best_v = Population[0][0].fitness_value
    best_a = 0
    best_b = 0

    New_Pop = []
    r = len(Population)

    for row in range(len(Population)):

        New_Row = []
        c = len(Population[row])

        for i in range(len(Population[row])):

            # Assemble expanded neighboorhood
            Extended_neigh = []
            Extended_neigh.append(Offspring_grid[row][i])

            if r_policy == '1to1SteadyState':
                Extended_neigh.append(Population[row][i])
                # Elite replacement policy
                new_cell = elite_selection(population=Extended_neigh, amount=1, minimization=minimization)[0]

            elif r_policy == 'Generational Replacement':
                new_cell = Offspring_grid[row][i]

            else:
                # allow neighbors migration
                neigh = []
                neigh.append(Population[row-1][i])
                neigh.append(Population[row][i-1])
                neigh.append(Population[row][i])
                neigh.append(Population[row][(i+1)%c])
                neigh.append(Population[(row+1)%r][i])
                if neighborhood == 'Moore':
                    neigh.append(Population[row-1][i-1])
                    neigh.append(Population[row-1][(i+1)%c])
                    neigh.append(Population[(row+1)%r][i-1])
                    neigh.append(Population[(row+1)%r][(i+1)%c])


                Extended_neigh.extend(neigh)
                # Elite replacement policy
                new_cell = elite_selection(population=Extended_neigh, amount=1, minimization=minimization)[0]


            New_Row.append(new_cell)

            L.append(new_cell.fitness_value)
            if minimization:
                if new_cell.fitness_value < best_v:
                    best_v = new_cell.fitness_value
                    best_a = row
                    best_b = i
            else:
                if new_cell.fitness_value > best_v:
                    best_v = new_cell.fitness_value
                    best_a = row
                    best_b = i


        # Append row

        New_Pop.append(New_Row)


    # Replace old Population

    Population = New_Pop


    # Count how many fitnesses are actually different
    no_different = len(set(L))
    # Diversity as a proportion of different fitnesses over population size
    diversity = no_different / len(L)

    best_fit = best_v


    if test_batch is not None:
        # Pick top performer
        top_individual = Population[best_a][best_b]
        # Test it against test set
        test_fit = top_individual.fitness(test_batch, test_labels)
        # Restore top individual fitness according to current generation training batch:
        top_individual.fitness(batch, labels)
    else:
        test_fit = None


    # Return best individual (for usage purposes)
    #result = elite_selection(population=New_Pop, amount=1, minimization=minimization)

    return New_Pop, diversity, best_fit, test_fit


def CellularMP(Population, batch, labels, test_batch, test_labels, l_rate, oper, oper_prob, oper_arity, minimization, sel_mechanism, online, pro, neighborhood='von Neumann', beta=-1, r_policy='1to1SteadyState'):
    '''Same as Cellular model, but with support for multiple processors usage, just as Steady_State and Steady_StateMP.
    It should be stressed though, that unlike many Cellular models described in the literature, this is not a fully
    parallel model: just as in the case of Steady_StateMP, only the individuals evaluation is performed in parallel by
    using all CPUs allocated through the 'pro' parameter, i.e. genetic operations (crossover, mutation, etc.) are not
    performed in parallel.

    Although in the literature this model is always described as optimal for distributed systems and parallelization,
    in practice, parallel implementation of genetic operations is difficult, -at least in Python. Island models can
    take more advantage systems with multiple processors, because such models partially parallelize genetic operations
    as well. For systems with 8 processing threads and above, it is suggested to use island models rather than this
    cellular model, or carefully calibrate batch sizes against pop size, so most of the CPUs do not remain idle most
    of the time while waiting for a single CPU to perform genetic operations.'''

    np.random.seed()
    random.seed()

    # Process every cell

    Offspring_grid = []
    r = len(Population)

    for row in range(len(Population)):

        New_Row = []
        c = len(Population[row])

        for i in range(len(Population[row])):

            # create neighborhood
            neigh = []

            if np.random.uniform() <= beta:

                neigh.append(Population[row][i])
                operation = np.random.choice(a=list(range(len(oper))), p=oper_prob)
                gpoperation = oper[operation]
                arity = oper_arity[operation]
                parents_minipool = elite_selection(population=neigh, amount=1, minimization=minimization)

            else:

                #neigh.append(Population[row-1][i-1])
                neigh.append(Population[row-1][i])
                #neigh.append(Population[row-1][(i+1)%c])

                neigh.append(Population[row][i-1])
                neigh.append(Population[row][i])
                neigh.append(Population[row][(i+1)%c])

                #neigh.append(Population[(row+1)%r][i-1])
                neigh.append(Population[(row+1)%r][i])
                #neigh.append(Population[(row+1)%r][(i+1)%c])

                if neighborhood == 'Moore':

                    neigh.append(Population[row-1][i-1])
                    neigh.append(Population[row-1][(i+1)%c])

                    neigh.append(Population[(row+1)%r][i-1])
                    neigh.append(Population[(row+1)%r][(i+1)%c])

                operation = np.random.choice(a=list(range(len(oper))), p=oper_prob)
                gpoperation = oper[operation]
                arity = oper_arity[operation]
                parents_minipool = sel_mechanism(population=neigh, proportion=l_rate, minimization=minimization)


            # Create and evaluate offspring
            #Offspring = []

            # Pick parents
            parents = [random.choice(parents_minipool) for _ in range(arity)]
            # Cross/Mutate them
            offsprings = gpoperation(*parents)

            if type(offsprings) is tuple:
                # there can be only one
                Offspring = np.random.choice(offsprings)
            else:
                Offspring = offsprings

            # Append Offspring
            New_Row.append(Offspring)

        # Append row
        Offspring_grid.append(New_Row)



    #-------------------------------------------------------------------------------------------
    #------------------- Parallel Multiprocessor Individuals Evaluation-------------------------
    #-------------------------------------------------------------------------------------------

    # arrange in linear lists
    linear_Population = []
    linear_Offspring_grid = []

    for a in range(len(Population)):
        for b in range(len(Population[a])):
            linear_Population.append(Population[a][b])

    for a in range(len(Offspring_grid)):
        for b in range(len(Offspring_grid[a])):
            linear_Offspring_grid.append(Offspring_grid[a][b])


    # Evaluate in parallel
    with Pool(pro) as p:

        func = partial(evaluate_fitness_in_parallel,
                       batch = batch,
                       labels = labels)

        if online == True:
            Population_fitnesses = p.map(func, linear_Population)
        Offspring_fitnesses = p.map(func, linear_Offspring_grid)

    # Assign fitness values manually
    if online == True:
        for i in range(len(linear_Population)):
            linear_Population[i].fitness_value = Population_fitnesses[i]
    for i in range(len(linear_Offspring_grid)):
        linear_Offspring_grid[i].fitness_value = Offspring_fitnesses[i]

    #--------------------------------------------------------------------------------------------
    #--------------------------------------------------------------------------------------------




    # Build next pop

    L = []
    best_v = Population[0][0].fitness_value
    best_a = 0
    best_b = 0

    New_Pop = []
    r = len(Population)

    for row in range(len(Population)):

        New_Row = []
        c = len(Population[row])

        for i in range(len(Population[row])):

            # Assemble expanded neighboorhood
            Extended_neigh = []
            Extended_neigh.append(Offspring_grid[row][i])

            if r_policy == '1to1SteadyState':
                Extended_neigh.append(Population[row][i])
                # Elite replacement policy
                new_cell = elite_selection(population=Extended_neigh, amount=1, minimization=minimization)[0]

            elif r_policy == 'Generational Replacement':
                new_cell = Offspring_grid[row][i]

            else:
                # allow neighbors migration
                neigh = []
                neigh.append(Population[row-1][i])
                neigh.append(Population[row][i-1])
                neigh.append(Population[row][i])
                neigh.append(Population[row][(i+1)%c])
                neigh.append(Population[(row+1)%r][i])
                if neighborhood == 'Moore':
                    neigh.append(Population[row-1][i-1])
                    neigh.append(Population[row-1][(i+1)%c])
                    neigh.append(Population[(row+1)%r][i-1])
                    neigh.append(Population[(row+1)%r][(i+1)%c])


                Extended_neigh.extend(neigh)
                # Elite replacement policy
                new_cell = elite_selection(population=Extended_neigh, amount=1, minimization=minimization)[0]


            New_Row.append(new_cell)

            L.append(new_cell.fitness_value)
            if minimization:
                if new_cell.fitness_value < best_v:
                    best_v = new_cell.fitness_value
                    best_a = row
                    best_b = i
            else:
                if new_cell.fitness_value > best_v:
                    best_v = new_cell.fitness_value
                    best_a = row
                    best_b = i


        # Append row

        New_Pop.append(New_Row)


    # Replace old Population

    Population = New_Pop


    # Count how many fitnesses are actually different
    no_different = len(set(L))
    # Diversity as a proportion of different fitnesses over population size
    diversity = no_different / len(L)

    best_fit = best_v


    if test_batch is not None:
        # Pick top performer
        top_individual = Population[best_a][best_b]
        # Test it against test set
        test_fit = top_individual.fitness(test_batch, test_labels)
        # Restore top individual fitness according to current generation training batch:
        top_individual.fitness(batch, labels)
    else:
        test_fit = None


    # Return best individual (for usage purposes)
    #result = elite_selection(population=New_Pop, amount=1, minimization=minimization)

    return New_Pop, diversity, best_fit, test_fit



def Cellular_preEvalation(Population, batch, labels, test_batch, test_labels, l_rate, oper, oper_prob, oper_arity, minimization, sel_mechanism, online, neighborhood='von Neumann', beta=-1, r_policy='1to1SteadyState'):
    '''In this variant of the cellular population arragement, evaluation of the parents happen with the
    current mini-batch. In all other version of Cellular and non-Celullar (steady-state, etc.), online
    mode implies that the parents pool is assembled using the fitness value obtained in the immediately
    previous generation, i.e. the previous mini-batch, rather than using the current mini-batch fitness,
    in other words, the offspring is generated using the fitness score of another mini-batch, instead of
    using the current one, even though both current pop and offspring pool are later evaluated against
    the current mini batch in order to select survivors for the next gen. Here in contrast, the current
    population is evaluated agains the current mini-batch BEFORE offspring generation takes places, so
    everything is done within the same generation/minibatch.

    The consequences of such lag in the other models has not been studied thoroughly, nor contrasted
    against the behavior of the model herein presented; nevertheless -and therefore- this model is left
    to the user to experiment on her/his own account and see if there is any observeable difference
    between both approaches. NOTE: Steady State (non-cellular) pre-evaluation models is not currently
    provided, but it should be relatively simply to implement using as template the standard steady-
    state function provided (just moving to the top of the funciton the part where the current pop
    is evaluated).'''

    np.random.seed()
    random.seed()

    # evaluate original grid
    if online == True:
        for a in range(len(Population)):
            for b in range(len(Population[a])):
                Population[a][b].fitness(batch, labels)


    # Process every cell

    L = []
    best_v = Population[0][0].fitness_value
    best_a = 0
    best_b = 0


    New_Pop = []
    r = len(Population)

    for row in range(len(Population)):

        New_Row = []
        c = len(Population[row])

        for i in range(len(Population[row])):

            # create neighborhood
            neigh = []

            if np.random.uniform() <= beta:

                neigh.append(Population[row][i])
                operation = np.random.choice(a=list(range(len(oper))), p=oper_prob)
                gpoperation = oper[operation]
                arity = oper_arity[operation]
                parents_minipool = elite_selection(population=neigh, amount=1, minimization=minimization)

            else:

                #neigh.append(Population[row-1][i-1])
                neigh.append(Population[row-1][i])
                #neigh.append(Population[row-1][(i+1)%c])

                neigh.append(Population[row][i-1])
                neigh.append(Population[row][i])
                neigh.append(Population[row][(i+1)%c])

                #neigh.append(Population[(row+1)%r][i-1])
                neigh.append(Population[(row+1)%r][i])
                #neigh.append(Population[(row+1)%r][(i+1)%c])

                if neighborhood == 'Moore':

                    neigh.append(Population[row-1][i-1])
                    neigh.append(Population[row-1][(i+1)%c])

                    neigh.append(Population[(row+1)%r][i-1])
                    neigh.append(Population[(row+1)%r][(i+1)%c])

                operation = np.random.choice(a=list(range(len(oper))), p=oper_prob)
                gpoperation = oper[operation]
                arity = oper_arity[operation]
                parents_minipool = sel_mechanism(population=neigh, proportion=l_rate, minimization=minimization)


            # Create and evaluate offspring
            #Offspring = []

            # Pick parents
            parents = [random.choice(parents_minipool) for _ in range(arity)]
            # Cross/Mutate them
            offsprings = gpoperation(*parents)

            if type(offsprings) is tuple:
                # there can be only one
                Offspring = np.random.choice(offsprings)
            else:
                Offspring = offsprings


            # Evaluate Offspring
            Offspring.fitness(batch, labels)


            # Assemble expanded neighboorhood
            Extended_neigh = []
            Extended_neigh.append(Offspring)

            if r_policy == '1to1SteadyState':
                Extended_neigh.append(Population[row][i])
                # Elite replacement policy
                new_cell = elite_selection(population=Extended_neigh, amount=1, minimization=minimization)[0]

            elif r_policy == 'Generational Replacement':
                new_cell = Offspring

            else:
                # allow neighbors migration
                Extended_neigh.extend(neigh)
                # Elite replacement policy
                new_cell = elite_selection(population=Extended_neigh, amount=1, minimization=minimization)[0]


            New_Row.append(new_cell)

            L.append(new_cell.fitness_value)
            if minimization:
                if new_cell.fitness_value < best_v:
                    best_v = new_cell.fitness_value
                    best_a = row
                    best_b = i
            else:
                if new_cell.fitness_value > best_v:
                    best_v = new_cell.fitness_value
                    best_a = row
                    best_b = i


        # Append row

        New_Pop.append(New_Row)


    # Replace old Population

    Population = New_Pop


    # Count how many fitnesses are actually different
    no_different = len(set(L))
    # Diversity as a proportion of different fitnesses over population size
    diversity = no_different / len(L)

    best_fit = best_v


    if test_batch is not None:
        # Pick top performer
        top_individual = Population[best_a][best_b]
        # Test it against test set
        test_fit = top_individual.fitness(test_batch, test_labels)
        # Restore top individual fitness according to current generation training batch:
        top_individual.fitness(batch, labels)
    else:
        test_fit = None


    # Return best individual (for usage purposes)
    #result = elite_selection(population=New_Pop, amount=1, minimization=minimization)

    return New_Pop, diversity, best_fit, test_fit

def RHC(Population, batch, labels, test_batch, test_labels, l_rate, oper, oper_prob, oper_arity, minimization, sel_mechanism, online, pro=None, v_policy='random'):
    ''' "Recombinative Hill Climbing" implementation (population based, non-evolutionary) model.
    Based on the work of Hooper, Dale C., Flann Nicholas S., & Stephanie R. Fuller.'''

    np.random.seed()
    random.seed()

    pop_size = len(Population)

    visitors = list(range(pop_size))

    if v_policy == 'random_shift':
        for _ in range(np.random.randint(pop_size)):
            visitors.insert(0, visitors.pop())
    else:
        # Full Random shuffle
        random.shuffle(visitors)

    # Create offspring
    Offspring = []

    for i in range(pop_size):

        operation = np.random.choice(a=list(range(len(oper))), p=oper_prob)
        gpoperation = oper[operation]
        arity = oper_arity[operation]
        parents_minipool = [Population[i], Population[visitors[i]]]

        # Pick parents
        parents = [parents_minipool[a] for a in range(arity)]
        # Cross/Mutate them
        offsprings = gpoperation(*parents)

        if type(offsprings) is tuple:
            # there can be only one
            Offspring.append(np.random.choice(offsprings))
        else:
            Offspring.append(offsprings)


    # Now we have to evaluate both, the offspring and the original pop (because it is a mini batch training approach)
    if online == True:
        for individual in Population:
            individual.fitness(batch, labels)
    for individual in Offspring:
        individual.fitness(batch, labels)

    # Create container for new pop
    New_Pop = []

    for i in range(pop_size):
        if minimization:
            if Offspring[i].fitness_value <= Population[i].fitness_value:
                New_Pop.append(Offspring[i])
            else:
                New_Pop.append(Population[i])
        else:
            if Offspring[i].fitness_value >= Population[i].fitness_value:
                New_Pop.append(Offspring[i])
            else:
                New_Pop.append(Population[i])


    # Enumerate all fitnesses:
    L = []
    for individual in New_Pop:
        L.append(individual.fitness_value)
    # Count how many fitnesses are actually different
    no_different = len(set(L))
    # Diversity as a proportion of different fitnesses over population size
    diversity = no_different / len(New_Pop)

    if minimization:
        best_fit = min(L)
    else:
        best_fit = max(L)


    if test_batch is not None:
        # Pick top performer
        top_individual = elite_selection(population=Population, amount=1, minimization=minimization)[0]
        # Test it against test set
        test_fit = top_individual.fitness(test_batch, test_labels)
        # Restore top individual fitness according to current generation training batch:
        top_individual.fitness(batch, labels)
    else:
        test_fit = None


    # Return best individual (for usage purposes)
    #result = elite_selection(population=New_Pop, amount=1, minimization=minimization)

    return New_Pop, diversity, best_fit, test_fit


def RHCMP(Population, batch, labels, test_batch, test_labels, l_rate, oper, oper_prob, oper_arity, minimization, sel_mechanism, online, pro, v_policy='random'):
    ''' "Recombinative Hill Climbing" implementation (population based, non-evolutionary) model.
    Based on the work of Hooper, Dale C., Flann Nicholas S., & Stephanie R. Fuller.'''

    np.random.seed()
    random.seed()

    pop_size = len(Population)

    visitors = list(range(pop_size))

    if v_policy == 'random_shift':
        for _ in range(np.random.randint(pop_size)):
            visitors.insert(0, visitors.pop())
    else:
        # Full Random shuffle
        random.shuffle(visitors)

    # Create offspring
    Offspring = []

    for i in range(pop_size):

        operation = np.random.choice(a=list(range(len(oper))), p=oper_prob)
        gpoperation = oper[operation]
        arity = oper_arity[operation]
        parents_minipool = [Population[i], Population[visitors[i]]]

        # Pick parents
        parents = [parents_minipool[a] for a in range(arity)]
        # Cross/Mutate them
        offsprings = gpoperation(*parents)

        if type(offsprings) is tuple:
            # there can be only one
            Offspring.append(np.random.choice(offsprings))
        else:
            Offspring.append(offsprings)


    #-------------------------------------------------------------------------------------------
    #------------------- Parallel Multiprocessor Individuals Evaluation-------------------------
    #-------------------------------------------------------------------------------------------

    with Pool(pro) as p:

        func = partial(evaluate_fitness_in_parallel,
                       batch = batch,
                       labels = labels)

        if online == True:
            Population_fitnesses = p.map(func, Population)
        Offspring_fitnesses = p.map(func, Offspring)

    # Assign fitness values manually
    if online == True:
        for i in range(len(Population)):
            Population[i].fitness_value = Population_fitnesses[i]
    for i in range(len(Offspring)):
        Offspring[i].fitness_value = Offspring_fitnesses[i]

    #--------------------------------------------------------------------------------------------
    #--------------------------------------------------------------------------------------------

    # Create container for new pop
    New_Pop = []

    for i in range(pop_size):
        if minimization:
            if Offspring[i].fitness_value <= Population[i].fitness_value:
                New_Pop.append(Offspring[i])
            else:
                New_Pop.append(Population[i])
        else:
            if Offspring[i].fitness_value >= Population[i].fitness_value:
                New_Pop.append(Offspring[i])
            else:
                New_Pop.append(Population[i])


    # Enumerate all fitnesses:
    L = []
    for individual in New_Pop:
        L.append(individual.fitness_value)
    # Count how many fitnesses are actually different
    no_different = len(set(L))
    # Diversity as a proportion of different fitnesses over population size
    diversity = no_different / len(New_Pop)

    if minimization:
        best_fit = min(L)
    else:
        best_fit = max(L)


    if test_batch is not None:
        # Pick top performer
        top_individual = elite_selection(population=Population, amount=1, minimization=minimization)[0]
        # Test it against test set
        test_fit = top_individual.fitness(test_batch, test_labels)
        # Restore top individual fitness according to current generation training batch:
        top_individual.fitness(batch, labels)
    else:
        test_fit = None


    # Return best individual (for usage purposes)
    #result = elite_selection(population=New_Pop, amount=1, minimization=minimization)

    return New_Pop, diversity, best_fit, test_fit
